{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e923898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# 04_Model_CAC_30.ipynb\n",
    "# Entrenamiento con split temporal para CAC_source_30\n",
    "# ----------------------------------------------\n",
    "\n",
    "#  Inicialización\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Añadir src al path para importar los scripts\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'src')))\n",
    "\n",
    "#  Imports del script\n",
    "from train import (\n",
    "    load_and_prepare_data,\n",
    "    build_preprocessor,\n",
    "    train_models,\n",
    "    train_stacking_model,\n",
    "    save_models\n",
    ")\n",
    "\n",
    "#   Cargar datos y definir cortes\n",
    "df = pd.read_csv(\"../data/processed/final_dataset.csv\", parse_dates=[\"first_session\"])\n",
    "df = df[df[\"first_session\"] < \"2018-07-01\"]\n",
    "df = df[~df[\"CAC_source_30\"].isna()]\n",
    "\n",
    "# Split temporal manual\n",
    "train_df = df[df[\"first_session\"] < \"2018-01-01\"]\n",
    "test_df  = df[(df[\"first_session\"] >= \"2018-01-01\") & (df[\"first_session\"] < \"2018-07-01\")]\n",
    "\n",
    "# Preparar features y targets\n",
    "target = \"CAC_source_30\"\n",
    "drop_cols = ['uid', 'first_session', 'last_session', 'first_order', 'last_order',\n",
    "             'LTV_180', 'CAC_source_30', 'ltv_cohort_avg', 'cac_cohort_avg', 'conversion_rate_cohort']\n",
    "\n",
    "X_train = train_df.drop(columns=drop_cols, errors='ignore')\n",
    "y_train = train_df[target]\n",
    "\n",
    "X_test = test_df.drop(columns=drop_cols, errors='ignore')\n",
    "y_test = test_df[target]\n",
    "\n",
    "#   Preprocesamiento automático\n",
    "preprocessor = build_preprocessor(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d527f354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelos base y avanzados...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2377\n",
      "[LightGBM] [Info] Number of data points in the train set: 23174, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 6296.056221\n",
      "Entrenando modelo ensamblado (stacking)...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2377\n",
      "[LightGBM] [Info] Number of data points in the train set: 23174, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 6296.056221\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2358\n",
      "[LightGBM] [Info] Number of data points in the train set: 18539, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 6282.456550\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2353\n",
      "[LightGBM] [Info] Number of data points in the train set: 18539, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 6315.656794\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2362\n",
      "[LightGBM] [Info] Number of data points in the train set: 18539, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 6292.274192\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2359\n",
      "[LightGBM] [Info] Number of data points in the train set: 18539, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 6298.552624\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2361\n",
      "[LightGBM] [Info] Number of data points in the train set: 18540, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 6291.341199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pmate\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=2.14167e-22): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "#  Entrenar modelos individuales\n",
    "print(\"Entrenando modelos base y avanzados...\")\n",
    "modelos = train_models(X_train, y_train, preprocessor)\n",
    "\n",
    "#   Modelo ensamblado (stacking)\n",
    "print(\"Entrenando modelo ensamblado (stacking)...\")\n",
    "stacked_model = train_stacking_model(X_train, y_train, preprocessor, modelos)\n",
    "modelos[\"stacking\"] = stacked_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a33898d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando modelos en carpeta /models...\n",
      "Modelos guardados exitosamente en ../models/\n",
      " Entrenamiento completado. Test set disponible para evaluación.\n"
     ]
    }
   ],
   "source": [
    "#  Guardar modelos\n",
    "print(\"Guardando modelos en carpeta /models...\")\n",
    "save_models(modelos, target_name=\"CAC_source_30\", save_path=\"../models/\")\n",
    "\n",
    "print(\" Entrenamiento completado. Test set disponible para evaluación.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
